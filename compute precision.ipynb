{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit\n",
    "from scipy.ndimage import label\n",
    "from tifffile import imread, imsave\n",
    "from glob import glob\n",
    "from scipy import ndimage\n",
    "from skimage.measure import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def pixel_sharing_bipartite(lab1, lab2):\n",
    "    assert lab1.shape == lab2.shape\n",
    "    psg = np.zeros((lab1.max()+1, lab2.max()+1), dtype=np.int)\n",
    "    for i in range(lab1.size):\n",
    "        psg[lab1.flat[i], lab2.flat[i]] += 1\n",
    "    return psg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matching_iou(psg, fraction=0.5):\n",
    "    iou = intersection_over_union(psg)\n",
    "    matching = iou > fraction\n",
    "    matching[:,0] = False\n",
    "    matching[0,:] = False\n",
    "    return matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matching_max(psg):\n",
    "    \"\"\"\n",
    "    matching based on mutual first preference\n",
    "    \"\"\"\n",
    "    rowmax = np.argmax(psg, axis=0)\n",
    "    colmax = np.argmax(psg, axis=1)\n",
    "    starting_index = np.arange(psg.shape[1])\n",
    "    equal_matches = colmax[rowmax[starting_index]]==starting_index\n",
    "    rm, cm = rowmax[equal_matches], colmax[rowmax[equal_matches]]\n",
    "    matching = np.zeros_like(psg)\n",
    "    matching[rm, cm] = 1\n",
    "    return matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersection_over_union(psg):\n",
    "    rsum = np.sum(psg, 0, keepdims=True)\n",
    "    csum = np.sum(psg, 1, keepdims=True)\n",
    "    return psg / (rsum + csum - psg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matching_overlap(psg, fractions=(0.5,0.5)):\n",
    "    \"\"\"\n",
    "    create a matching given pixel_sharing_bipartite of two label images based on mutually overlapping regions of sufficient size.\n",
    "    NOTE: a true matching is only gauranteed for fractions > 0.5. Otherwise some cells might have deg=2 or more.\n",
    "    NOTE: doesnt break when the fraction of pixels matching is a ratio only slightly great than 0.5? (but rounds to 0.5 with float64?)\n",
    "    \"\"\"\n",
    "    afrac, bfrac = fractions\n",
    "    set0_object_sizes = np.sum(psg, axis=1, keepdims=True)\n",
    "    m0  = np.where(set0_object_sizes==0,0,psg / set0_object_sizes)\n",
    "    set1_object_sizes = np.sum(psg, axis=0, keepdims=True)\n",
    "    m1 = np.where(set1_object_sizes==0,0,psg / set1_object_sizes)\n",
    "    m0 = m0 > afrac\n",
    "    m1 = m1 > bfrac\n",
    "    matching = m0 * m1\n",
    "    matching = matching.astype('bool')\n",
    "    return matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(lab_gt, lab, iou=0.5, partial_dataset=False):\n",
    "    '''\n",
    "    precision = TP / (TP + FP + FN) i.e. \"intersection over union\" for a graph matching\n",
    "    '''\n",
    "    \n",
    "    psg = pixel_sharing_bipartite(lab_gt, lab)\n",
    "    matching = matching_iou(psg, fraction=iou)\n",
    "    assert matching.sum(0).max() < 2\n",
    "    assert matching.sum(1).max() < 2\n",
    "    n_gt  = len(set(np.unique(lab_gt)) - {0})\n",
    "    n_hyp = len(set(np.unique(lab)) - {0})\n",
    "    n_matched = matching.sum()\n",
    "#     print(\"TP:\", n_matched, \"FP:\", n_hyp-n_matched, \"FN:\", n_gt-n_matched)\n",
    "    if partial_dataset:\n",
    "        return n_matched , (n_gt + n_hyp - n_matched)\n",
    "    else:\n",
    "        return n_matched / (n_gt + n_hyp - n_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## full scores\n",
    "def seg(lab_gt, lab, partial_dataset=False):\n",
    "    \"\"\"\n",
    "    calculate seg from pixel_sharing_bipartite\n",
    "    seg is the average conditional-iou across ground truth cells\n",
    "    conditional-iou gives zero if not in matching\n",
    "    ----\n",
    "    calculate conditional intersection over union (CIoU) from matching & pixel_sharing_bipartite\n",
    "    for a fraction > 0.5 matching. Any CIoU between matching pairs will be > 1/3. But there may be some\n",
    "    IoU as low as 1/2 that don't match, and thus have CIoU = 0.\n",
    "    \"\"\"\n",
    "    psg = pixel_sharing_bipartite(lab_gt, lab)\n",
    "    iou = intersection_over_union(psg)\n",
    "    matching = matching_overlap(psg, fractions=(0.5, 0))\n",
    "    matching[0,:] = False\n",
    "    matching[:,0] = False\n",
    "    n_gt = len(set(np.unique(lab_gt)) - {0})\n",
    "    n_matched = iou[matching].sum()\n",
    "    if partial_dataset:\n",
    "        return n_matched , n_gt\n",
    "    else:\n",
    "        return n_matched / n_gt, (2* (n_matched / n_gt)/(1+(n_matched / n_gt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prakash/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEG score : 0.79259697644\n",
      "DICE score : 0.882969141742\n"
     ]
    }
   ],
   "source": [
    "gt_segs_path = glob(\"/Users/prakash/Desktop/MetaSeg_Data_Version1/CTC_GOWT1/SEG/*.tif\")\n",
    "label_segs_path = glob(\"/Users/prakash/Desktop/MetaSeg_Data_Version1/CTC_GOWT1/BIC/*.tif\")\n",
    "\n",
    "seg_scores_per_time = []\n",
    "dice_scores_per_time = []\n",
    "for i in range(len(gt_segs_path)):\n",
    "    seg_score, dice_score = seg(imread(gt_segs_path[i]), imread(label_segs_path[i]).astype(np.uint16))\n",
    "#     print(seg_score, dice_score)\n",
    "    seg_scores_per_time.append(seg_score)\n",
    "    dice_scores_per_time.append(dice_score)\n",
    "\n",
    "print(\"SEG score :\", np.mean(np.array(seg_scores_per_time) ))\n",
    "print(\"DICE score :\", np.mean(np.array(dice_scores_per_time) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AP score is:  0.704688041852\n"
     ]
    }
   ],
   "source": [
    "average_precision_score_list = []\n",
    "thresholds = np.arange(0.5,0.95,0.05)\n",
    "\n",
    "for thresh in thresholds:\n",
    "    gt_segs_path = glob(\"/Users/prakash/Desktop/MetaSeg_Data_Version1/CTC_GOWT1/SEG/*.tif\")[:50]\n",
    "    label_segs_path = glob(\"/Users/prakash/Desktop/MetaSeg_Data_Version1/CTC_GOWT1/runs/run3/50annotations/*.tif\")[:50]\n",
    "    sum_seg = 0\n",
    "    scores_per_time = []\n",
    "    for i in range(len(gt_segs_path)):\n",
    "        score = precision(imread(label_segs_path[i]).astype(np.uint16), imread(gt_segs_path[i]), thresh)\n",
    "        scores_per_time.append(score)\n",
    "        if(0<=score<=1):\n",
    "            sum_seg = sum_seg + score\n",
    "            \n",
    "    average_precision_score = sum_seg/len(gt_segs_path)\n",
    "    average_precision_score_list.append(average_precision_score)\n",
    "    \n",
    "#     print(\"AP score for threshold \"+str(thresh)+\" :\", average_precision_score )\n",
    "    \n",
    "print(\"Mean AP score is: \", np.mean(np.array(average_precision_score_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AP score is:  0.692107628024\n"
     ]
    }
   ],
   "source": [
    "average_precision_score_list = []\n",
    "thresholds = np.arange(0.5,0.95,0.05)\n",
    "for thresh in thresholds:\n",
    "    \n",
    "    gt_segs_path = glob(\"/Users/prakash/Desktop/MetaSeg_Data_Version1/CTC_GOWT1/SEG/*.tif\")[:50]\n",
    "    label_segs_path = glob(\"/Users/prakash/Desktop/MetaSeg_Data_Version1/CTC_GOWT1/BIC/*.tif\")[:50]\n",
    "    sum_seg = 0\n",
    "    scores_per_time = []\n",
    "    for i in range(len(gt_segs_path)):\n",
    "        score = precision(imread(label_segs_path[i]).astype(np.uint16), imread(gt_segs_path[i]), thresh)\n",
    "        scores_per_time.append(score)\n",
    "        if(0<=score<=1):\n",
    "            sum_seg = sum_seg + score\n",
    "            \n",
    "    average_precision_score = sum_seg/len(gt_segs_path)\n",
    "    average_precision_score_list.append(average_precision_score)\n",
    "#     print(\"AP score for threshold \"+str(thresh)+\" :\", average_precision_score )\n",
    "\n",
    "print(\"Mean AP score is: \", np.mean(np.array(average_precision_score_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
